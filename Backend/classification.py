# -*- coding: utf-8 -*-
"""Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19hiaB0MIFctb7T5Uep2gGLb7Vyo8sKwZ

#Clothing Apprarel Classification
"""

# Import needed libraries
import numpy as np
from keras.datasets import fashion_mnist

"""

```
Using Tensorflow as our Backend
```

"""

# Load fashion MNIST dataset
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

# Explore the dataset
# Checking shape /size of each train and their test
print("Number of samples/observations in training data: " + str(len(x_train)))
print("Number of labels in training data: " + str(len(y_train)))
print("Dimensions of single image in x_train: " + str(x_train[0].shape))
print("---------------------------------------------------------------------")
print("Number of samples/observations in test data: " + str(len(x_test)))
print("Number of labels in test data: " + str(len(y_test)))
print("Dimensions of single image in x_test: " + str(x_test[0].shape))

"""#View Sample Images

"""

# Visualization library to visualize images
import matplotlib.pyplot as plt

# Plotting 5 images, Subplot arguments represents nrows, ncols, and index
# Color map is set to grey since our image dataset will be greyscale
plt.subplot(231)
random_num = np.random.randint(0, len(x_train))
plt.imshow(x_train[random_num], cmap = plt.get_cmap('gray'))

plt.subplot(232)
random_num = np.random.randint(0, len(x_train))
plt.imshow(x_train[random_num], cmap = plt.get_cmap('gray'))

plt.subplot(233)
random_num = np.random.randint(0, len(x_train))
plt.imshow(x_train[random_num], cmap = plt.get_cmap('gray'))

plt.subplot(234)
random_num = np.random.randint(0, len(x_train))
plt.imshow(x_train[random_num], cmap = plt.get_cmap('gray'))

plt.subplot(235)
random_num = np.random.randint(0, len(x_train))
plt.imshow(x_train[random_num], cmap = plt.get_cmap('gray'))

# Visualize the images
plt.show()

# Import necessary keras specific libraries
from keras.utils import np_utils
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization
from keras import backend as K

# Setting Training Parameters like batch_size and epochs
batch_size = 128
epochs = 100

# Storing numbers from rows and columns
img_rows = x_train[0].shape[0]
img_cols = x_train[1].shape[0]

# Data being put into the right shape as it is required by Keras means to change the dimension of (60000, 28, 28) to (60000, 28, 28, 1)
x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)

# Store the shape of single image
input_shape = (img_rows, img_cols, 1)

# Change the image type to a float32 type
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

# Change the range from (0 - 255) to (0 - 1)
x_train /= 255
x_test /= 255

# Hot encoding performed
y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)

# Number of pixls and classes calculated
num_classes = y_test.shape[1]
num_pixels = x_train.shape[1] * x_train.shape[2]

# CNN Model is created here
model = Sequential()

model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape))

model.add(BatchNormalization())

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(BatchNormalization())

model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(BatchNormalization())

model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))

model.compile(loss = 'categorical_crossentropy',
              optimizer = keras.optimizers.Adadelta(),
              metrics = ['accuracy'])

print(model.summary())

"""#Time To Train the Model"""

model_fitting = model.fit(x_train, y_train,
                          batch_size = batch_size,
                          epochs = epochs,
                          verbose = 1,
                          validation_data = (x_test, y_test))

score = model.evaluate(x_test, y_test, verbose = 0)
print('Test loss: ', score[0])
print('Test accuracy', score[1])

# Mount the google drive
from google.colab import drive
drive.mount('/content/drive')

# Change the directory to current working directory
import os
os.chdir("/content/drive/My Drive/Colab Notebooks")

# Save the model with a name needed to upload
model.save('clothing_classification.h5')