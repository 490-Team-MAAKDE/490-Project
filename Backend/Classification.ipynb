{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Clothing Apprarel Classification\n"
      ],
      "metadata": {
        "id": "c47CXYET-rXy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "TNdDcir5-juv"
      },
      "outputs": [],
      "source": [
        "# Import needed libraries\n",
        "import numpy as np\n",
        "from keras.datasets import fashion_mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Using Tensorflow as our Backend\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "HJAG0Fam_ziN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load fashion MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "DD_XgGzi-o9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a7d9d76-8b85-442d-cad5-d6605e22fbcd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the dataset\n",
        "# Checking shape /size of each train and their test\n",
        "print(\"Number of samples/observations in training data: \" + str(len(x_train)))\n",
        "print(\"Number of labels in training data: \" + str(len(y_train)))\n",
        "print(\"Dimensions of single image in x_train: \" + str(x_train[0].shape))\n",
        "print(\"---------------------------------------------------------------------\")\n",
        "print(\"Number of samples/observations in test data: \" + str(len(x_test)))\n",
        "print(\"Number of labels in test data: \" + str(len(y_test)))\n",
        "print(\"Dimensions of single image in x_test: \" + str(x_test[0].shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLbOI53zDFur",
        "outputId": "e2063e44-a65a-4203-d012-502681d452a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples/observations in training data: 60000\n",
            "Number of labels in training data: 60000\n",
            "Dimensions of single image in x_train: (28, 28)\n",
            "---------------------------------------------------------------------\n",
            "Number of samples/observations in test data: 10000\n",
            "Number of labels in test data: 10000\n",
            "Dimensions of single image in x_test: (28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#View Sample Images\n"
      ],
      "metadata": {
        "id": "m5xDTxWbGOew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization library to visualize images\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting 5 images, Subplot arguments represents nrows, ncols, and index\n",
        "# Color map is set to grey since our image dataset will be greyscale\n",
        "plt.subplot(231)\n",
        "random_num = np.random.randint(0, len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap = plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(232)\n",
        "random_num = np.random.randint(0, len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap = plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(233)\n",
        "random_num = np.random.randint(0, len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap = plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(234)\n",
        "random_num = np.random.randint(0, len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap = plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(235)\n",
        "random_num = np.random.randint(0, len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap = plt.get_cmap('gray'))\n",
        "\n",
        "# Visualize the images\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "4lWmENjbGTZE",
        "outputId": "1b546878-51ea-48fe-fb1e-7f664bc3c17b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary keras specific libraries\n",
        "from keras.utils import np_utils\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras import backend as K\n",
        "\n",
        "# Setting Training Parameters like batch_size and epochs\n",
        "batch_size = 128\n",
        "epochs = 100\n",
        "\n",
        "# Storing numbers from rows and columns\n",
        "img_rows = x_train[0].shape[0]\n",
        "img_cols = x_train[1].shape[0]\n",
        "\n",
        "# Data being put into the right shape as it is required by Keras means to change the dimension of (60000, 28, 28) to (60000, 28, 28, 1)\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "# Store the shape of single image\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# Change the image type to a float32 type\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Change the range from (0 - 255) to (0 - 1)\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Hot encoding performed\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# Number of pixls and classes calculated\n",
        "num_classes = y_test.shape[1]\n",
        "num_pixels = x_train.shape[1] * x_train.shape[2]\n",
        "\n",
        "# CNN Model is created here\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = keras.optimizers.Adadelta(),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af5rtiapRtuT",
        "outputId": "850e579c-70c4-404c-9ca0-b59c5cbbb03b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 26, 26, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 24, 24, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1179776   \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,200,778\n",
            "Trainable params: 1,200,330\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Time To Train the Model"
      ],
      "metadata": {
        "id": "uxm7Bj5LZE2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_fitting = model.fit(x_train, y_train,\n",
        "                          batch_size = batch_size,\n",
        "                          epochs = epochs,\n",
        "                          verbose = 1,\n",
        "                          validation_data = (x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose = 0)\n",
        "print('Test loss: ', score[0])\n",
        "print('Test accuracy', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x44IPX5ZI4U",
        "outputId": "17604088-bfbe-48f2-df5f-c613eb3c3366"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 14s 12ms/step - loss: 2.5697 - accuracy: 0.2751 - val_loss: 1.4846 - val_accuracy: 0.5152\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.5764 - accuracy: 0.5036 - val_loss: 0.8846 - val_accuracy: 0.6986\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.2684 - accuracy: 0.5960 - val_loss: 0.7704 - val_accuracy: 0.7319\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 1.1040 - accuracy: 0.6445 - val_loss: 0.7023 - val_accuracy: 0.7552\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.0021 - accuracy: 0.6748 - val_loss: 0.6563 - val_accuracy: 0.7715\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.9383 - accuracy: 0.6923 - val_loss: 0.6233 - val_accuracy: 0.7810\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.8858 - accuracy: 0.7099 - val_loss: 0.5985 - val_accuracy: 0.7894\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.8512 - accuracy: 0.7196 - val_loss: 0.5781 - val_accuracy: 0.7964\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.8056 - accuracy: 0.7329 - val_loss: 0.5607 - val_accuracy: 0.8036\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.7886 - accuracy: 0.7393 - val_loss: 0.5455 - val_accuracy: 0.8089\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.7542 - accuracy: 0.7481 - val_loss: 0.5339 - val_accuracy: 0.8128\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.7373 - accuracy: 0.7538 - val_loss: 0.5223 - val_accuracy: 0.8173\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.7208 - accuracy: 0.7610 - val_loss: 0.5127 - val_accuracy: 0.8208\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.7008 - accuracy: 0.7646 - val_loss: 0.5024 - val_accuracy: 0.8257\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.6891 - accuracy: 0.7700 - val_loss: 0.4956 - val_accuracy: 0.8283\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.6724 - accuracy: 0.7729 - val_loss: 0.4876 - val_accuracy: 0.8310\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.6621 - accuracy: 0.7785 - val_loss: 0.4823 - val_accuracy: 0.8326\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.6498 - accuracy: 0.7811 - val_loss: 0.4760 - val_accuracy: 0.8337\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.6397 - accuracy: 0.7862 - val_loss: 0.4698 - val_accuracy: 0.8355\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.6293 - accuracy: 0.7880 - val_loss: 0.4640 - val_accuracy: 0.8378\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.6234 - accuracy: 0.7895 - val_loss: 0.4590 - val_accuracy: 0.8399\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.6121 - accuracy: 0.7930 - val_loss: 0.4547 - val_accuracy: 0.8409\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.6084 - accuracy: 0.7961 - val_loss: 0.4505 - val_accuracy: 0.8419\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5975 - accuracy: 0.8001 - val_loss: 0.4472 - val_accuracy: 0.8431\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5901 - accuracy: 0.8004 - val_loss: 0.4425 - val_accuracy: 0.8451\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5851 - accuracy: 0.8017 - val_loss: 0.4391 - val_accuracy: 0.8468\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5789 - accuracy: 0.8056 - val_loss: 0.4358 - val_accuracy: 0.8477\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5717 - accuracy: 0.8072 - val_loss: 0.4329 - val_accuracy: 0.8495\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5699 - accuracy: 0.8073 - val_loss: 0.4292 - val_accuracy: 0.8510\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5620 - accuracy: 0.8112 - val_loss: 0.4267 - val_accuracy: 0.8515\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5578 - accuracy: 0.8107 - val_loss: 0.4235 - val_accuracy: 0.8528\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5511 - accuracy: 0.8123 - val_loss: 0.4208 - val_accuracy: 0.8542\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5429 - accuracy: 0.8167 - val_loss: 0.4182 - val_accuracy: 0.8547\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5433 - accuracy: 0.8162 - val_loss: 0.4150 - val_accuracy: 0.8562\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5411 - accuracy: 0.8168 - val_loss: 0.4133 - val_accuracy: 0.8567\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.5357 - accuracy: 0.8193 - val_loss: 0.4107 - val_accuracy: 0.8571\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5310 - accuracy: 0.8220 - val_loss: 0.4082 - val_accuracy: 0.8580\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5315 - accuracy: 0.8217 - val_loss: 0.4060 - val_accuracy: 0.8579\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5264 - accuracy: 0.8204 - val_loss: 0.4039 - val_accuracy: 0.8588\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5210 - accuracy: 0.8221 - val_loss: 0.4013 - val_accuracy: 0.8601\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5142 - accuracy: 0.8253 - val_loss: 0.3996 - val_accuracy: 0.8601\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5105 - accuracy: 0.8258 - val_loss: 0.3977 - val_accuracy: 0.8608\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5050 - accuracy: 0.8290 - val_loss: 0.3956 - val_accuracy: 0.8613\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5062 - accuracy: 0.8284 - val_loss: 0.3936 - val_accuracy: 0.8622\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4979 - accuracy: 0.8305 - val_loss: 0.3919 - val_accuracy: 0.8624\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4944 - accuracy: 0.8313 - val_loss: 0.3899 - val_accuracy: 0.8630\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4987 - accuracy: 0.8305 - val_loss: 0.3881 - val_accuracy: 0.8638\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4931 - accuracy: 0.8314 - val_loss: 0.3871 - val_accuracy: 0.8644\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4913 - accuracy: 0.8334 - val_loss: 0.3853 - val_accuracy: 0.8641\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4836 - accuracy: 0.8348 - val_loss: 0.3839 - val_accuracy: 0.8646\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4815 - accuracy: 0.8365 - val_loss: 0.3823 - val_accuracy: 0.8643\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4797 - accuracy: 0.8377 - val_loss: 0.3800 - val_accuracy: 0.8662\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4799 - accuracy: 0.8377 - val_loss: 0.3785 - val_accuracy: 0.8671\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4752 - accuracy: 0.8391 - val_loss: 0.3773 - val_accuracy: 0.8677\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4771 - accuracy: 0.8383 - val_loss: 0.3760 - val_accuracy: 0.8672\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4705 - accuracy: 0.8406 - val_loss: 0.3748 - val_accuracy: 0.8676\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4654 - accuracy: 0.8404 - val_loss: 0.3729 - val_accuracy: 0.8677\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4649 - accuracy: 0.8413 - val_loss: 0.3714 - val_accuracy: 0.8681\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4641 - accuracy: 0.8422 - val_loss: 0.3709 - val_accuracy: 0.8681\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4671 - accuracy: 0.8419 - val_loss: 0.3690 - val_accuracy: 0.8695\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4638 - accuracy: 0.8422 - val_loss: 0.3679 - val_accuracy: 0.8695\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4621 - accuracy: 0.8429 - val_loss: 0.3667 - val_accuracy: 0.8706\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4550 - accuracy: 0.8456 - val_loss: 0.3659 - val_accuracy: 0.8704\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4521 - accuracy: 0.8458 - val_loss: 0.3640 - val_accuracy: 0.8709\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4542 - accuracy: 0.8455 - val_loss: 0.3630 - val_accuracy: 0.8715\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.4498 - accuracy: 0.8467 - val_loss: 0.3621 - val_accuracy: 0.8718\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4474 - accuracy: 0.8479 - val_loss: 0.3610 - val_accuracy: 0.8721\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4479 - accuracy: 0.8490 - val_loss: 0.3604 - val_accuracy: 0.8716\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4475 - accuracy: 0.8482 - val_loss: 0.3584 - val_accuracy: 0.8721\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4410 - accuracy: 0.8498 - val_loss: 0.3572 - val_accuracy: 0.8735\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4450 - accuracy: 0.8482 - val_loss: 0.3564 - val_accuracy: 0.8731\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.4358 - accuracy: 0.8507 - val_loss: 0.3554 - val_accuracy: 0.8731\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.4349 - accuracy: 0.8502 - val_loss: 0.3542 - val_accuracy: 0.8736\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.4354 - accuracy: 0.8509 - val_loss: 0.3533 - val_accuracy: 0.8733\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.4366 - accuracy: 0.8504 - val_loss: 0.3527 - val_accuracy: 0.8742\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4310 - accuracy: 0.8535 - val_loss: 0.3518 - val_accuracy: 0.8742\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4312 - accuracy: 0.8534 - val_loss: 0.3508 - val_accuracy: 0.8750\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4275 - accuracy: 0.8522 - val_loss: 0.3492 - val_accuracy: 0.8750\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4278 - accuracy: 0.8532 - val_loss: 0.3488 - val_accuracy: 0.8756\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4276 - accuracy: 0.8541 - val_loss: 0.3477 - val_accuracy: 0.8759\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4239 - accuracy: 0.8541 - val_loss: 0.3468 - val_accuracy: 0.8765\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4236 - accuracy: 0.8554 - val_loss: 0.3461 - val_accuracy: 0.8767\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4223 - accuracy: 0.8546 - val_loss: 0.3452 - val_accuracy: 0.8769\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4176 - accuracy: 0.8564 - val_loss: 0.3445 - val_accuracy: 0.8773\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4153 - accuracy: 0.8586 - val_loss: 0.3431 - val_accuracy: 0.8773\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4172 - accuracy: 0.8577 - val_loss: 0.3422 - val_accuracy: 0.8773\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4127 - accuracy: 0.8590 - val_loss: 0.3419 - val_accuracy: 0.8779\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4110 - accuracy: 0.8581 - val_loss: 0.3413 - val_accuracy: 0.8779\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4153 - accuracy: 0.8576 - val_loss: 0.3401 - val_accuracy: 0.8784\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4099 - accuracy: 0.8591 - val_loss: 0.3390 - val_accuracy: 0.8783\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4109 - accuracy: 0.8602 - val_loss: 0.3383 - val_accuracy: 0.8788\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4081 - accuracy: 0.8612 - val_loss: 0.3377 - val_accuracy: 0.8782\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4077 - accuracy: 0.8595 - val_loss: 0.3370 - val_accuracy: 0.8787\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4093 - accuracy: 0.8595 - val_loss: 0.3363 - val_accuracy: 0.8797\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4039 - accuracy: 0.8598 - val_loss: 0.3358 - val_accuracy: 0.8802\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.4020 - accuracy: 0.8616 - val_loss: 0.3347 - val_accuracy: 0.8802\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4021 - accuracy: 0.8629 - val_loss: 0.3337 - val_accuracy: 0.8802\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4040 - accuracy: 0.8620 - val_loss: 0.3328 - val_accuracy: 0.8806\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4042 - accuracy: 0.8615 - val_loss: 0.3324 - val_accuracy: 0.8807\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3975 - accuracy: 0.8628 - val_loss: 0.3315 - val_accuracy: 0.8817\n",
            "Test loss:  0.3315410017967224\n",
            "Test accuracy 0.8816999793052673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYM1sDsZefvk",
        "outputId": "8b006f67-096d-4054-b93f-8ec29e42149a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the directory to current working directory\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ],
      "metadata": {
        "id": "EScLhMfFs8xz"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model with a name needed to upload\n",
        "model.save('clothing_classification.h5')"
      ],
      "metadata": {
        "id": "brHRwzX3wi7P"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}